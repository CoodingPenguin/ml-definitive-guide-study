{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection 모듈 소개\n",
    "사이킷런의 `model_selection` 모듈은 다음과 같은 기능을 제공하는 함수 및 클래스를 제공한다.\n",
    "- 학습 데이터와 테스트 데이터 세트를 분리\n",
    "- 교차 검증 분할 및 평가\n",
    "- Estimator의 하이퍼 파라미터를 튜닝 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 학습/테스트 데이터 세트 분리 - train_test_split()\n",
    "학습과 예측을 위한 데이터 세트로 동일한 데이터 세트를 사용하면 제대로된 예측을 수행할 수 없다. 이렇게 되면 정확도가 100%로 마치 '시험지 정답을 보고 시험을 본 것'과 같다. 그러므로 데이터 세트를 학습용 데이터 세트와 예측을 위한 테스트 데이터 세트로 나누어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도 :  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()    # 데이터셋 로딩\n",
    "dt_clf = DecisionTreeClassifier()    # 의사결정트리 객체\n",
    "train_data = iris.data       # feature 데이터 값\n",
    "train_label = iris.target    # 결과 데이터 값\n",
    "dt_clf.fit(train_data, train_label)    # 학습\n",
    "\n",
    "# 학습 데이터 세트로 예측 수행\n",
    "pred = dt_clf.predict(train_data)\n",
    "print('예측 정확도 : ', accuracy_score(train_label, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 세트를 학습용 데이터 세트와 테스트용 데이터 세트로 분리할 때 `train_test_split()`를 이용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_test_split(데이터.data, 데이터.target, test_size=0.3, random_state=131)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `test_size` : 테스트 데이터 세트 크기 (디폴드값은 0.25)\n",
    "- `train_size` : 학습용 데이터 세트 크기 (test_size로 비율을 설정하므로 거의 쓰이지 않음)\n",
    "- `shuffle` : 데이터 분리 전에 데이터를 미리 섞을지 결정 (디폴드값은 True)\n",
    "- `random_state` : 동일한 학습/테스트용 데이터 세트를 생성하기 위한 seed값 (`train_test_split()` 호출할 때 마다 seed값이 달라지므로 동일하게 분리하기 위한 같은 값으로 지정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도 : 0.955556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "iris_data = load_iris()\n",
    "\n",
    "# 테스트 데이터 셋은 30%\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.3, random_state=121)\n",
    "dt_clf.fit(X_train, y_train)     # 학습\n",
    "pred = dt_clf.predict(X_test)    # 테스트용 데이터셋으로 예측\n",
    "print('예측 정확도 : {0:4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습을 위한 데이터의 양을 일정 수준 이상으로 보장하는 것도 좋지만, 학습된 모델을 가지고 예측 성능을 평가해보는 것도 중요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 교차 검증\n",
    "Overfitting이란 학습된 모델이 **학습된 데이터에만 과도하게 최적화**되어 실제 예측 시 새로운 데이터를 넣으면 성능이 떨어지는 것을 말한다. Overfitting은 똑같은 데이터 세트로 계속해서 반복 학습을 할 경우 발생하며 이는 여러 세트로 구성된 학습 데이터과 검증 데이터 세트를 통해 학습과 평가를 하는 **교차 검증**으로 해결할 수 있다.     \n",
    "즉, 교차 검증은 테스트 데이터 세트와 학습 데이터 세트로 분리한 뒤, 학습 데이터 세트의 일부를 **검증 데이터 세트**로 두어 미리 평가를 하는 것이다. 최종 평가는 테스트 데이터 세트로 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. K 폴드 교차 검증\n",
    "가장 보편적인 교차 검증 기법으로 K개의 데이터 폴드 세트를 만들어 K번만큼 각 폴드 세트에 대해 학습과 검증 평가를 반복적으로 수행하는 방법이다.   \n",
    "1. K개의 폴드된 데이터 세트를 학습 데이터 세트와 검증 데이터 세트로 나눈다.\n",
    "2. 나누어진 데이터 세트로 K번 평가를 수행한다.\n",
    "3. K개의 평가의 평균을 가지고 예측 성능을 평가한다.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![K 폴드 교차 검증](./k_fold_cross_validation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트 크기 :  150\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "# 5개의 폴드 세트로 분리하는 KFold 객체와 폴드 세트별 정확도를 저장하는 리스트 생성\n",
    "kfold = KFold(n_splits=5)\n",
    "cv_accuracy = []\n",
    "print('붓꽃 데이터 세트 크기 : ', features.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`split()`을 호출하면 데이터 세트를 K개의 폴드 데이터 세트로 분리한다. 그 때 학습용/검증용 데이터로 분할한 인덱스들을 `ndarray` 형태로 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차 검증 정확도 : 1.0, 학습 데이터 크기 : 120, 검증 데이터 크기 : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "#1 검증 세트 : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "#2 교차 검증 정확도 : 0.9667, 학습 데이터 크기 : 120, 검증 데이터 크기 : [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "#2 검증 세트 : [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "\n",
      "#3 교차 검증 정확도 : 0.8667, 학습 데이터 크기 : 120, 검증 데이터 크기 : [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "#3 검증 세트 : [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "\n",
      "#4 교차 검증 정확도 : 0.9333, 학습 데이터 크기 : 120, 검증 데이터 크기 : [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "#4 검증 세트 : [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "\n",
      "#5 교차 검증 정확도 : 0.7333, 학습 데이터 크기 : 120, 검증 데이터 크기 : [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "#5 검증 세트 : [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "## 평균 검증 정확도 :  0.9\n"
     ]
    }
   ],
   "source": [
    "n_iter = 0\n",
    "\n",
    "# KFold 객체의 split()를 호출하면 폴드 별 학습용, 검증용 테스트의 인덱스를 array로 반환\n",
    "for train_index, test_index in kfold.split(features):\n",
    "    # kfold.split()에서 반환된 인덱스로 학습용, 검증용 데이터를 추출\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    \n",
    "    # 학습 및 예측\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    n_iter += 1\n",
    "    \n",
    "    # 반복할 때마다 정확도 측정\n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print('\\n#{0} 교차 검증 정확도 : {1}, 학습 데이터 크기 : {2}, 검증 데이터 크기 : {3}'.format(n_iter, accuracy, train_size, test_index))\n",
    "    print('#{0} 검증 세트 : {1}'.format(n_iter, test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "# 개별 iteration 별 정확도를 합하여 평균 정확도 계산\n",
    "print('\\n## 평균 검증 정확도 : ', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Stratified K 폴드\n",
    "![Stratified K Fold](./stratified_k_fold.png)\n",
    "\n",
    "Stratified K 폴드는 불균형한 분포도를 가진 레이블 데이터 집합을 위한 K 폴드 방식이다. 불균형한 분포도를 가진 레이블 데이터 집합은 **특정 레이블 값이 특이하게 많거나 매우 적어서 분포가 한쪽으로 치우치는 것**을 말한다.  \n",
    "예를 들어 스팸 메일일 경우 1을, 아닐 경우 0인 레이블 데이터 있다고 하자. 스팸 메일일 확률을 0.0001%로 데이터 세트의 극히 일부이다. 만약 이 0.0001%가 데이터 세트의 한 쪽에 몰려 있다면, 모델은 스팸 메일이 아닌 걸 주로 학습을 할 것이다.    \n",
    "\n",
    "이를 방지하기 위해 **원본 데이터의 레이블 분포를 먼저 고려한 뒤 이 분포와 동일하게 학습과 검증 데이터 세트를 분배**하는 Stratified K 폴드 방식을 적용하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 레이블 분포도 확인\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)    # feature 데이터 값을 DataFrame으로 생성\n",
    "iris_df['label']=iris.target       # 레이블 데이터를 저장할 'lable' column 생성 및 값 저장 \n",
    "iris_df['label'].value_counts()    # 각 레이블 값의 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## 교차 검증 : 1\n",
      "학습 레이블 데이터 분포 : \n",
      " 2    50\n",
      "1    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 0    50\n",
      "Name: label, dtype: int64\n",
      "\n",
      "## 교차 검증 : 2\n",
      "학습 레이블 데이터 분포 : \n",
      " 2    50\n",
      "0    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 1    50\n",
      "Name: label, dtype: int64\n",
      "\n",
      "## 교차 검증 : 3\n",
      "학습 레이블 데이터 분포 : \n",
      " 1    50\n",
      "0    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 2    50\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# K Fold 방식 적용시 학습/검증 레이블 데이터 값의 분포도 확인\n",
    "kfold = KFold(n_splits=3)\n",
    "n_iter = 0\n",
    "for train_index, test_index in kfold.split(iris_df):\n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    \n",
    "    print('\\n## 교차 검증 : {0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포 : \\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포 : \\n', label_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 결과를 보았을 때 검증 데이터의 레이블 값은 학습 데이터의 레이블 값에 없는 값이므로 결국 검증 정확도가 0이 되어 버린다. 그래서 레이블 값의 분포도를 반영하여 검증을 하는 Stratified KFold 방법을 사용하면 이 문제를 해결할 수 있다.     \n",
    "Stratified K Fold 방식은 KFold 방식은 딱 한 가지가 다른데 레이블 데이터 분포도에 따라 학습/검증 데이터를 나누기 때문에 **`split()` 메서드의 인자로 피처 데이터 세트뿐만 아니라 레이블 데이터 세트도 포함**해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차 검증 : 1\n",
      "학습 레이블 데이터 분포 : \n",
      " 2    33\n",
      "1    33\n",
      "0    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 2    17\n",
      "1    17\n",
      "0    17\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증 : 2\n",
      "학습 레이블 데이터 분포 : \n",
      " 2    33\n",
      "1    33\n",
      "0    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 2    17\n",
      "1    17\n",
      "0    17\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증 : 3\n",
      "학습 레이블 데이터 분포 : \n",
      " 2    34\n",
      "1    34\n",
      "0    34\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 2    16\n",
      "1    16\n",
      "0    16\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print('## 교차 검증 : {0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포 : \\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포 : \\n', label_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차 검증 정확도 : 0.9804, 학습 데이터 크기 : 99, 검증 데이터 크기 : 51\n",
      "#1 검증 세트 인덱스 : [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116]\n",
      "\n",
      "#2 교차 검증 정확도 : 0.9216, 학습 데이터 크기 : 99, 검증 데이터 크기 : 51\n",
      "#2 검증 세트 인덱스 : [ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
      "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133]\n",
      "\n",
      "#3 교차 검증 정확도 : 0.9792, 학습 데이터 크기 : 102, 검증 데이터 크기 : 48\n",
      "#3 검증 세트 인덱스 : [ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  84  85\n",
      "  86  87  88  89  90  91  92  93  94  95  96  97  98  99 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "## 교차 검증별 정확도 :  [0.9804 0.9216 0.9792]\n",
      "## 평균 검증 정확도 :  0.9604\n"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "skfold = StratifiedKFold(n_splits=3)\n",
    "n_iter=0\n",
    "cv_accuracy = []\n",
    "\n",
    "# 레이블 값 분포도를 파악해야 하므로 label 데이터도 넘겨주어야 한다\n",
    "for train_index, test_index in skfold.split(features, label):\n",
    "    # split()으로 반환된 인덱스를 이용해 학습/검증용 테스트 데이터 추출\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    \n",
    "    # 학습 및 예측\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    \n",
    "    # 반복할 때마다 정확도 측정\n",
    "    n_iter += 1\n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    \n",
    "    print('\\n#{0} 교차 검증 정확도 : {1}, 학습 데이터 크기 : {2}, 검증 데이터 크기 : {3}'.format(n_iter, accuracy, train_size, test_size))\n",
    "    print('#{0} 검증 세트 인덱스 : {1}'.format(n_iter, test_index))\n",
    "    \n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "# 교차 검증별 정확도 및 평균 정확도 계산\n",
    "print('\\n## 교차 검증별 정확도 : ', np.round(cv_accuracy, 4))\n",
    "print('## 평균 검증 정확도 : ', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 불균등한 분포의 레이블 데이터 세트를 가진다면 반드시 **Stratified K 폴드**를 이용해 교차검증을 해야 한다. \n",
    "* 분류(Classification)에서는 **Stratified K 폴드**로 분할되어야 한다. \n",
    "* 회귀(Regression)의 경우 결과값이 연속된 숫자값이기 때문에 결과값의 분포도를 고려할 필요가 없으므로 Stratified K 폴드가 지원되지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. 교차 검증을 보다 편하게 - `cross_val_score()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이킷런은 교차 검증을 좀 더 편리하게 수행할 수 있는 API를 제공하는데 `cross_val_score()`를 사용하면 보다 쉽게 교차 검증을 할 수 있다. `cross_val_score()`는 아래 3가지 과정을 한 번에 수행해주는 함수이다.\n",
    "1. 폴드 세트를 설정\n",
    "2. for문에서 반복적으로 학습 및 테스트 데이터의 인덱스를 추출 \n",
    "3. 반복적으로 학습과 예측을 수행\n",
    "4. 예측 성능 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cross_val_score(estimator, X, y=None, scoring=None, cv=None, n_jobs=1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')**\n",
    "- `estimator` : Classifier나 Regressor\n",
    "- `X` : 피처 데이터 세트\n",
    "- `y` : 레이블 데이터 세트\n",
    "- `scoring` : 예측 성능 평가 지표\n",
    "- `cv` : 교차 검증 폴드 수    \n",
    "\n",
    "`scoring`으로 지정된 성능 지표 측정값을 배열 형태로 반환한다. 이 때 `classifier`가 입력되면 Stratified K 폴드 방식으로 분할을 하고 `regressor`가 입력되면 Stratified K 폴드 방식을 쓸 수 없으므로 K 폴드 방식으로 분할한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도 :  [0.9804 0.9216 0.9792]\n",
      "평균 검증 정확도 :  0.9604\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "data = iris_data.data\n",
    "label = iris_data.target\n",
    "\n",
    "# 성능 지표는 accuracy, 교차 검증 세트는 3개\n",
    "scores = cross_val_score(dt_clf, data, label, scoring='accuracy', cv=3)\n",
    "print('교차 검증별 정확도 : ', np.round(scores, 4))\n",
    "print('평균 검증 정확도 : ', np.round(np.mean(scores), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cross_val_score()`는 하나의 평가 지표만 가능하다. 만약 여러 개의 평가 지표를 반환하고 싶을 경우 `cross_validate()`를 사용하면 되며 수행시간도 같이 제공된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. GridSearchCV - 교차 검증과 최적 하이퍼 파라미터 튜닝을 한 번에\n",
    "하이퍼 파라미터란 머신러닝 알고리즘을 구성하는 주요 구성 요소이며, 이 값을 조정해 알고리즘의 예측 성능을 개선할 수 있다. `GridSearchCV`를 이용하면 `Classifier`나 `Regressor`와 같은 알고리즘에 하이퍼 파라미터를 **순차적으로** 입력하면서 최적의 파라미터를 도출해낸다.    \n",
    "* 사용자가 튜닝하고자 하는 어려 개의 하이퍼 파라미터를 다양하게 테스트하면서 쉽게 최적의 파라미터를 찾을 수 있다.\n",
    "* 하지만 순차적으로 테스트하므로 수행시간이 오래 걸린다.\n",
    "* `CV=3`, `max_depth=[1,2,3]`, `min_samples_split=[2,3]`이면 `3*3*2=18`의 학습/평가가 이루어진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GridSearchCV(estimator=`머신러닝 알고리즘`, param_grid=`테스트할 하이퍼 파라미터`, scoring=`예측 성능 지표`, cv=`폴드수`, refit=`True/False`)**\n",
    "* `estimator` : classifer, regressor, pipeline\n",
    "* `param_grid` : 문자열 key값과 리스트 value값을 가진 딕셔너리 형태이며, 튜닝을 위한 파라미터 명과 값들을 지정\n",
    "* `scoring` : 예측 성능을 측정할 평가 방법\n",
    "* `cv` : 교차 검증을 위해 분할되는 학습/테스트 세트의 개수\n",
    "* `refit` : `True`이면 최적의 하이퍼 파라미터로 `estimator` 객체를 재학습시킴 (디폴트값은 `True`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "iris_data = load_iris()    # 데이터 로딩\n",
    "\n",
    "# 학습/테스트 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.2, random_state=121)\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "# 파라미터를 딕셔너리 형태로 설정\n",
    "parameters = {'max_depth':[1,2,3], 'min_samples_split':[2,3]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 데이터 세트인 `X_train`을 GridSearchCV객체의 `fit`의 인자로 입력하면 다음과 같은 과정이 일어난다.\n",
    "1. `cv`에 기술된 폴딩 세트로 학습데이터를 분할\n",
    "2. `param_grid`에 기술된 하이퍼 파라미터를 순차적으로 변경하면서 학습/평가 수행\n",
    "3. `cv_results_` 속성에 결과를 기록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0              0.700                0.7               0.70  \n",
       "1              0.700                0.7               0.70  \n",
       "2              0.925                1.0               0.95  \n",
       "3              0.925                1.0               0.95  \n",
       "4              0.975                1.0               0.95  \n",
       "5              0.975                1.0               0.95  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# param_grid의 하이퍼 파라미터를 3개의 학습/테스트 폴드 세트로 나누어 설정\n",
    "grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True)\n",
    "\n",
    "# 붓꽃 학습 데이터로 param_grid의 하이퍼 파라미터를 순차적으로 학습/평가\n",
    "grid_dtree.fit(X_train, y_train)\n",
    "\n",
    "# GridSearchCV 결과를 추출해 DataFrame으로 변환\n",
    "score_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "score_df[['params', 'mean_test_score', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `param` : 수행할 때 마다 적용된 개별 하이퍼 파라미터값\n",
    "* `rank_test_score` : 하이퍼 파라미터별로 성능이 좋은 score 순위\n",
    "* `mean_test_score` : 개별 파라미터별로 각 폴드 데이터 세트의 평가 결과의 평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터 :  {'max_depth': 3, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 적확도 : 0.9750\n"
     ]
    }
   ],
   "source": [
    "print('GridSearchCV 최적 파라미터 : ', grid_dtree.best_params_)              # 최고 성능을 나타낸 하이퍼 파라미터 값\n",
    "print('GridSearchCV 최고 적확도 : {0:.4f}'.format(grid_dtree.best_score_))   # 그 때의 평과 결과값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 세트 정확도 : 0.966667\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV의 refit으로 이미 학습된 estimator 변환\n",
    "estimator = grid_dtree.best_estimator_     # 최적의 하이퍼 파라미터로 학습한 estimator\n",
    "\n",
    "# GridSearchCV의 best_estimator_는 이미 최적 학습이 되었으므로 별도 학습이 필요 없음\n",
    "pred = estimator.predict(X_test)\n",
    "print('테스트 데이터 세트 정확도 : {0:4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로 `GridSearchCV`를 이용해 최적 하이퍼 파라미터 튜닝을 한 뒤에 별도의 테스트 데이터 세트에서 이를 평가하는 것이 일반적이다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
